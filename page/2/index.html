<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Edlison</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Edlison">
<meta property="og:url" content="http://edlison.com/blog/page/2/index.html">
<meta property="og:site_name" content="Edlison">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Bolin Shen">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/blog/atom.xml" title="Edlison" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/blog/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/blog/" id="logo">Edlison</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/blog/" id="subtitle">coding...</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/blog/">Home</a>
        
          <a class="main-nav-link" href="/blog/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/blog/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://edlison.com/blog"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-nlp/week-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/07/26/nlp/week-2/" class="article-date">
  <time datetime="2020-07-26T10:28:47.408Z" itemprop="datePublished">2020-07-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/07/26/nlp/week-2/">nlp/week-2</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><p>深度学习与神经网络基础，pytorch基础。</p>
<h2 id="神经网络训练过程"><a href="#神经网络训练过程" class="headerlink" title="神经网络训练过程"></a>神经网络训练过程</h2><ul>
<li>将DataSet生成iter(train_iter, test_iter), 每个iter由X,y构成 (X:Sample的所有特征[samples * features], y:真实标签).</li>
<li>计算y_hat (y_hat:通过构造的神经网络模型得到的预测值).</li>
<li>计算损失函数 (均方差, 交叉熵).</li>
<li>对所有params梯度清零.</li>
<li>loss.backward反向传播, 对损失函数求梯度, 也就是得所有的到权重和偏置的梯度param.grad.</li>
<li>params带入梯度下降算法, 更新params.</li>
<li>每个epoch后, 将测试数据带入训练后的网络模型中计算准确率.</li>
</ul>
<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p><strong>1. W初始化</strong><br>首先介绍一下我们不应该做的事情（即初始化为0）。需要注意的是我们并不知道在训练神经网络中每一个权重最后的值，但是如果进行了恰当的数据归一化后，我们可以有理由认为有一半的权重是正的，另一半是负的。令所有权重都初始化为0这个一个听起来还蛮合理的想法也许是一个我们假设中最好的一个假设了。但结果正确是一个错误(的想法)，因为如果神经网络计算出来的输出值都一个样，那么反向传播算法计算出来的梯度值一样，并且参数更新值也一样(w=w−α∗dw)。更一般地说，如果权重初始化为同一个值，网络就不可能不对称(即是对称的)。</p>
<p><strong>2. 梯度清零</strong><br>每次反向传播前需要将params的梯度清零，否则每次计算的梯度为上一个梯度的累加。</p>
<p><strong>3. 反向传播</strong><br>计算的是给定图的叶子结点的梯度，对Loss函数进行反向传播计算所得即为所有的W与b。</p>
<p><strong>4. python方法</strong><br>method()代表执行完该函数<br>method仅函数对象</p>
<p><strong>5. 二分类问题不小心将最后一层设为10维</strong><br>最后训练出来的权重使得结果在0, 1上的概率更大，不排除最后的结果为2 ~ 9。</p>
<p><strong>6. 网络的层次</strong><br>每一层为激活函数</p>
<p>层数-1 为连接层 连接层对应[W, b]</p>
<p>X = [batch_size * features]  </p>
<ul>
<li><p>第一层输入为([-1, features])  </p>
</li>
<li><p>矩阵计算: [-1, features] * [W1(input_num, hidden_num)] + b1  </p>
</li>
<li><p>隐藏层输入为(input_num, hidden_num)  </p>
</li>
<li><p>矩阵计算: [-1, hidden_num] * [W2(hidden_num, output_num)] + b2  </p>
</li>
<li><p>输出层为(hidden_num, output_num)  </p>
</li>
<li><p>最终矩阵格式: [-1, output_num]</p>
</li>
</ul>
<p><strong>7. 特殊第一层input输入层</strong><br>输入的特征可能type为Long, 一定要转为float.<br>batch_size与input_num无关, 但features一定与input_num相等.</p>
<p><strong>8. X.permute</strong><br>model的forward必须要X.permute(1, 0)<br><code>LSTM(batch_first=True)</code>没用？？？</p>
<p><strong>9. python路径问题</strong><br>相对路径取决于调用该函数的python文件位置，不是子函数所在python文件相对于文件的位置。</p>
<p><strong>10. pytorch使用GPU计算</strong>  </p>
<ul>
<li>训练及评价集需要X.cuda()将数据移至GPU  </li>
<li>model与loss函数需要model.cuda(), loss.cuda()移至GPU</li>
</ul>
<p><strong>11. 导出数据</strong><br>TestLoader导出预测结果时，一定不能将导入的数据Shuffle!!!</p>
<p><strong>12. pad</strong><br><code>&lt;pad&gt;</code>对应一个随机生成的向量</p>
<p><strong>13. torch.no_grad()</strong>  </p>
<ul>
<li>requires_grad=True 要求计算梯度</li>
<li>requires_grad=False 不要求计算梯度</li>
<li>with torch.no_grad()或者@torch.no_grad()中的数据不需要计算梯度，也不会进行反向传播</li>
</ul>
<p>即使一个tensor（命名为x）的requires_grad = True，由x得到的新tensor（命名为w-标量）requires_grad也为False，且grad_fn也为None,即不会对w求导。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">10</span>, <span class="number">5</span>, requires_grad = <span class="literal">True</span>)</span><br><span class="line">y = torch.randn(<span class="number">10</span>, <span class="number">5</span>, requires_grad = <span class="literal">True</span>)</span><br><span class="line">z = torch.randn(<span class="number">10</span>, <span class="number">5</span>, requires_grad = <span class="literal">True</span>)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    w = x + y + z</span><br><span class="line">    print(w.requires_grad)</span><br><span class="line">    print(w.grad_fn)</span><br><span class="line">    print(w.requires_grad)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="literal">None</span></span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>

<p><strong>14. train()/eval()</strong>  </p>
<ul>
<li><p>在训练模型时，前面加上<code>model.train()</code><br>启用 BatchNormalization 和 Dropout</p>
</li>
<li><p>在测试模型时，前面加上<code>model.eval()</code><br>不启用 BatchNormalization 和 Dropout<br>即使不训练，它也会改变权值。这是model中含有batch normalization层所带来的的性质。</p>
</li>
</ul>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>最后一层输出不加激活函数 含义(最后预测值是数值最大的 因此没有影响)？？？</p>
<p>隐藏层没有激活函数 含义？？？</p>
<p><code>LSTM(batch_first=True)</code>没用？？？</p>
<p>embedding_layer(X)中X.shape为(batch,seq)或(seq,batch)没影响？？？<br>若batch_first了embedding后要(batch,seq)后传入rnn？？？</p>
<p>lstm门使用sigmoid代表门开程度，而不是四舍五入为0或1？？？</p>
<h2 id="词向量框架"><a href="#词向量框架" class="headerlink" title="词向量框架"></a>词向量框架</h2><ul>
<li>拿到每个样本</li>
<li>每个样本分词</li>
<li>构建词典{word: index}</li>
<li>对每个Sample标准化处理， 长度不足补<code>&lt;pad&gt;</code></li>
<li>将每个Sample中的word对应index，没有的对应<code>&lt;pad&gt;</code>的index</li>
<li>获取预训练的词向量</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://edlison.com/blog/2020/07/26/nlp/week-2/" data-id="ckd3h9jf00001rcojegdped30" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-notebook/docker-nextcloud" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/07/26/notebook/docker-nextcloud/" class="article-date">
  <time datetime="2020-07-25T17:48:17.756Z" itemprop="datePublished">2020-07-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/07/26/notebook/docker-nextcloud/">notebook/docker-nextcloud</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Docker-NextCloud"><a href="#Docker-NextCloud" class="headerlink" title="Docker-NextCloud"></a>Docker-NextCloud</h1><h2 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">version: &#39;3&#39;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  nextcloud:</span><br><span class="line">    image: nextcloud</span><br><span class="line">    restart: &quot;no&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - ~&#x2F;docker_nextcloud&#x2F;data&#x2F;:&#x2F;var&#x2F;www&#x2F;html</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;25000:80&quot;</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://edlison.com/blog/2020/07/26/notebook/docker-nextcloud/" data-id="ckd3h9jeu0000rcoj8qpq64oy" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-nlp/week-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/07/14/nlp/week-1/" class="article-date">
  <time datetime="2020-07-14T15:31:04.196Z" itemprop="datePublished">2020-07-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/07/14/nlp/week-1/">nlp/week-1</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="NLP文本分类引导"><a href="#NLP文本分类引导" class="headerlink" title="NLP文本分类引导"></a>NLP文本分类引导</h1><h2 id="1-数据读取"><a href="#1-数据读取" class="headerlink" title="1. 数据读取"></a>1. 数据读取</h2><h3 id="python原生读取txt文件"><a href="#python原生读取txt文件" class="headerlink" title="python原生读取txt文件"></a>python原生读取txt文件</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f = open(filedir, mode=<span class="string">'r'</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>f.read()</code>一次读取全部数据。</li>
<li><code>f.readline()</code>分行读取，一次读取一行。</li>
<li><code>f.readlines()</code>读取全部数据，保留<code>\n</code>换行符。</li>
</ul>
<h3 id="pandas读取txt文件"><a href="#pandas读取txt文件" class="headerlink" title="pandas读取txt文件"></a>pandas读取txt文件</h3><p>pd.read_table(filedir, splitsign, header=指定第几行为列名, names=如果没有列名手动指定[‘x’, ‘y’])</p>
<h2 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2. 数据预处理"></a>2. 数据预处理</h2><h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><h3 id="去除停词-去除低频词"><a href="#去除停词-去除低频词" class="headerlink" title="去除停词 去除低频词"></a>去除停词 去除低频词</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimize_words_dict</span><span class="params">(self, data, stop_words, threshold)</span>:</span></span><br><span class="line">    freq_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> data:  <span class="comment"># 去除停词 + 计算词频</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> line:</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> stop_words:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> freq_dict:</span><br><span class="line">                freq_dict[word] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                freq_dict[word] += <span class="number">1</span></span><br><span class="line">    words_list = []</span><br><span class="line">    values = sorted(list(set(freq_dict.values())), reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> values:  <span class="comment"># 通过阈值筛选词表 算法可以优化？？？</span></span><br><span class="line">        <span class="keyword">if</span> w &lt; threshold:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> freq_dict.items():</span><br><span class="line">            <span class="keyword">if</span> v == w:</span><br><span class="line">                words_list.append((k, v))</span><br><span class="line">    <span class="keyword">return</span> words_list</span><br></pre></td></tr></table></figure>

<h3 id="通过TF-IDF算法筛选单词"><a href="#通过TF-IDF算法筛选单词" class="headerlink" title="通过TF-IDF算法筛选单词"></a>通过TF-IDF算法筛选单词</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tf_idf</span><span class="params">(self, data)</span>:</span></span><br><span class="line">    doc_num = len(data)</span><br><span class="line">    df = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> sample <span class="keyword">in</span> data:</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> set(sample):  <span class="comment"># 避免一个单词在一个Sample里出现多次</span></span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> df:</span><br><span class="line">                df[word] = <span class="number">1.0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                df[word] += <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> df:  <span class="comment"># 计算document frequency 文档总数/单词出现过的文档数</span></span><br><span class="line">        df[word] = log10(doc_num / df[word])</span><br><span class="line">    res = &#123;&#125;</span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> sample <span class="keyword">in</span> data:</span><br><span class="line">        res[index] = &#123;&#125;</span><br><span class="line">        tf = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> sample:  <span class="comment"># 计算term frequency 一个样本里单词的频率</span></span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> tf:</span><br><span class="line">                tf[word] = <span class="number">1.0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                tf[word] += <span class="number">1.0</span></span><br><span class="line">        sample_len = len(sample)</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> sample:  <span class="comment"># 计算tf * idf 一个样本中各单词的tf_idf</span></span><br><span class="line">            tf_idf = tf[word] / sample_len * df[word]</span><br><span class="line">            res[index][word] = tf_idf</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res  <span class="comment"># res格式为每一个样本中每一个单词对应的tf_idf值</span></span><br></pre></td></tr></table></figure>

<p><strong>在预处理时，因为是要为生成词典做准备，所以TF-IDF应该是以整个corpus计算TF，而提取特征时建立词袋模型中的TF-IDF方法则是对每个Sample的单词计算TF-IDF值。</strong></p>
<h2 id="3-建立词典"><a href="#3-建立词典" class="headerlink" title="3. 建立词典"></a>3. 建立词典</h2><p>词典 = {‘单词’:索引}</p>
<h2 id="4-提取特征"><a href="#4-提取特征" class="headerlink" title="4. 提取特征"></a>4. 提取特征</h2><h3 id="词袋模型（BOW）"><a href="#词袋模型（BOW）" class="headerlink" title="词袋模型（BOW）"></a>词袋模型（BOW）</h3><p>假设建立的词典有1000维，那么我们将为数据集中的每一个Sample建立一个1000维的向量。</p>
<p>词袋模型有三种形式：</p>
<ul>
<li>对于每个Smaple单词是否出现</li>
<li>对于每个Sample单词出现次数</li>
<li>对于每个Smaple单词的TF-IDF值</li>
</ul>
<p><strong>在预处理时，因为是要为生成词典做准备，所以TF-IDF应该是以整个corpus计算TF，而提取特征时建立词袋模型中的TF-IDF方法则是对每个Sample的单词计算TF-IDF值。</strong></p>
<p>例：<br>词典：1000. [北京，天气，真，好，北京] = [0, 1, 0, …,0], 或 [0, 2, 0, …,0]，或 [0, 0.4, 0, …, 0]</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://edlison.com/blog/2020/07/14/nlp/week-1/" data-id="ckcltkatc0000wlojdnjm7fy8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-notebook/grpc" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/06/17/notebook/grpc/" class="article-date">
  <time datetime="2020-06-17T00:22:38.832Z" itemprop="datePublished">2020-06-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/06/17/notebook/grpc/">notebook/grpc</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="gRPC入门"><a href="#gRPC入门" class="headerlink" title="gRPC入门"></a>gRPC入门</h1><h2 id="下载依赖"><a href="#下载依赖" class="headerlink" title="下载依赖"></a>下载依赖</h2><p><code>pip install grpc</code><br><code>pip install proto</code><br><code>pip install grpc-tools</code>  </p>
<h2 id="设置接口"><a href="#设置接口" class="headerlink" title="设置接口"></a>设置接口</h2><p>在.proto文件中定义接口</p>
<h2 id="生成文件"><a href="#生成文件" class="headerlink" title="生成文件"></a>生成文件</h2><p><code>python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. api.proto</code></p>
<h2 id="proto示例"><a href="#proto示例" class="headerlink" title="proto示例"></a>proto示例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">syntax &#x3D; &quot;proto3&quot;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; The greeting service definition.</span><br><span class="line">service Greeter &#123;</span><br><span class="line">  &#x2F;&#x2F; Sends a greeting</span><br><span class="line">  rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;</span><br><span class="line">  &#x2F;&#x2F; Sends another greeting</span><br><span class="line">  rpc SayHelloAgain (HelloRequest) returns (HelloReply) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; The request message containing the user&#39;s name.</span><br><span class="line">message HelloRequest &#123;</span><br><span class="line">  string name &#x3D; 1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; The response message containing the greetings</span><br><span class="line">message HelloReply &#123;</span><br><span class="line">  string message &#x3D; 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="server示例"><a href="#server示例" class="headerlink" title="server示例"></a>server示例</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Greeter</span><span class="params">(api_pb2_grpc.GreeterServicer)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">SayHello</span><span class="params">(self, request, context)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> api_pb2.HelloReply(message=<span class="string">'Hello, %s!'</span> % request.name)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">SayHelloAgain</span><span class="params">(self, request, context)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> api_pb2.HelloReply(message=<span class="string">'Hello again, %s!'</span> % request.name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">serve</span><span class="params">()</span>:</span></span><br><span class="line">    server = grpc.server(futures.ThreadPoolExecutor(max_workers=<span class="number">4</span>))</span><br><span class="line">    api_pb2_grpc.add_GreeterServicer_to_server(Greeter(), server)</span><br><span class="line">    server.add_insecure_port(<span class="string">'localhost:50051'</span>)</span><br><span class="line">    server.start()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            time.sleep(<span class="number">60</span> * <span class="number">60</span> * <span class="number">24</span>)</span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">        server.stop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    serve()</span><br></pre></td></tr></table></figure>

<h2 id="client示例"><a href="#client示例" class="headerlink" title="client示例"></a>client示例</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">  channel = grpc.insecure_channel(<span class="string">'localhost:50051'</span>)</span><br><span class="line">  stub = api_pb2_grpc.GreeterStub(channel)</span><br><span class="line">  response = stub.SayHello(api_pb2.HelloRequest(name=<span class="string">'you'</span>))</span><br><span class="line">  print(<span class="string">"Greeter client received: "</span> + response.message)</span><br><span class="line">  response = stub.SayHelloAgain(api_pb2.HelloRequest(name=<span class="string">'you'</span>))</span><br><span class="line">  print(<span class="string">"Greeter client received: "</span> + response.message)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    run()</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://edlison.com/blog/2020/06/17/notebook/grpc/" data-id="ckbimehhx0000ixoj7ak6dgwc" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-notebook/docker-gitlab" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/29/notebook/docker-gitlab/" class="article-date">
  <time datetime="2020-05-28T16:27:08.074Z" itemprop="datePublished">2020-05-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/29/notebook/docker-gitlab/">notebook/docker-gitlab</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Docker-GitLab"><a href="#Docker-GitLab" class="headerlink" title="Docker-GitLab"></a>Docker-GitLab</h1><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>若容器端口号设置为80，如果你这时修改external_url地址为<a href="http://ip:8080" target="_blank" rel="noopener">http://ip:8080</a>.<br>那GitLab肯定访问不了，因为已经将内部的端口号修改为8080端口了，而映射的是容器的80端口。</p>
<h2 id="故一定要将容器内部端口号与宿主机端口号映射一致！！！"><a href="#故一定要将容器内部端口号与宿主机端口号映射一致！！！" class="headerlink" title="故一定要将容器内部端口号与宿主机端口号映射一致！！！"></a>故一定要将容器内部端口号与宿主机端口号映射一致！！！</h2><p>external_utl ‘<a href="http://119.23.107.61:13000&#39;">http://119.23.107.61:13000&#39;</a><br>ports:<br>      - “13000:13000”</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'3'</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">gitlab:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">gitlab/gitlab-ce</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">TZ:</span> <span class="string">"Asia/Shanghai"</span></span><br><span class="line">      <span class="attr">GITLAB_OMNIBUS_CONFIG:</span> <span class="string">|</span></span><br><span class="line">        <span class="string">external_url</span> <span class="string">'http://119.23.107.61:13000'</span> <span class="string">//</span> <span class="string">好像需要手动改</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">~/docker_gitlab/config:/etc/gitlab</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="string">~/docker_gitlab/logs:/var/log/gitlab</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="string">~/docker_gitlab/data:/var/opt/gitlab</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"13000:13000"</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"13443:443"</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"13022:22"</span></span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://edlison.com/blog/2020/05/29/notebook/docker-gitlab/" data-id="ckar2gyw40001x2ojaprocdg0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-notebook/docker-compose" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/28/notebook/docker-compose/" class="article-date">
  <time datetime="2020-05-28T14:21:43.661Z" itemprop="datePublished">2020-05-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/28/notebook/docker-compose/">notebook/docker-compose</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker-Compose"></a>Docker-Compose</h1><h2 id="运行指令"><a href="#运行指令" class="headerlink" title="运行指令"></a>运行指令</h2><p><code>docker-compose</code>指令执行当前文件夹下docker-compose.yml文件</p>
<p>项目运行<br><code>docker-compose up -d</code></p>
<p>项目停止<br><code>docker-compose down</code></p>
<h2 id="挂载"><a href="#挂载" class="headerlink" title="挂载"></a>挂载</h2><p>volumes声明过的名称才能用在镜像的volumes挂载<br>镜像中volumes挂载地址也可以使用相对路径</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://edlison.com/blog/2020/05/28/notebook/docker-compose/" data-id="ckar2gyvz0000x2oj620zb72r" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-mlsec/KNN-手写体数字数据集" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/17/mlsec/KNN-%E6%89%8B%E5%86%99%E4%BD%93%E6%95%B0%E5%AD%97%E6%95%B0%E6%8D%AE%E9%9B%86/" class="article-date">
  <time datetime="2020-05-17T08:37:20.000Z" itemprop="datePublished">2020-05-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/17/mlsec/KNN-%E6%89%8B%E5%86%99%E4%BD%93%E6%95%B0%E5%AD%97%E6%95%B0%E6%8D%AE%E9%9B%86/">mlsec/KNN-手写体数字数据集</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="KNN-手写体数字数据集"><a href="#KNN-手写体数字数据集" class="headerlink" title="KNN-手写体数字数据集"></a>KNN-手写体数字数据集</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">digits = datasets.load_digits()</span><br><span class="line">X = digits.data</span><br><span class="line">X.shape</span><br></pre></td></tr></table></figure>




<pre><code>(1797, 64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = digits.target</span><br><span class="line">y.shape</span><br></pre></td></tr></table></figure>




<pre><code>(1797,)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">one = X[<span class="number">100</span>]</span><br><span class="line">one = one.reshape(<span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">one</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 0.,  0.,  0.,  2., 13.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  8., 15.,  0.,  0.,  0.],
       [ 0.,  0.,  5., 16.,  5.,  2.,  0.,  0.],
       [ 0.,  0., 15., 12.,  1., 16.,  4.,  0.],
       [ 0.,  4., 16.,  2.,  9., 16.,  8.,  0.],
       [ 0.,  0., 10., 14., 16., 16.,  4.,  0.],
       [ 0.,  0.,  0.,  0., 13.,  8.,  0.,  0.],
       [ 0.,  0.,  0.,  0., 13.,  6.,  0.,  0.]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(one)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.image.AxesImage at 0x1a203a9ad0&gt;</code></pre><p><img src="data/output_5_1.png" alt="png"></p>
<h1 id="分离训练测试集"><a href="#分离训练测试集" class="headerlink" title="分离训练测试集"></a>分离训练测试集</h1><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_test_split?</span><br></pre></td></tr></table></figure>


<pre><code>[0;31mSignature:[0m [0mtrain_test_split[0m[0;34m([0m[0;34m*[0m[0marrays[0m[0;34m,[0m [0;34m**[0m[0moptions[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;31mDocstring:[0m
Split arrays or matrices into random train and test subsets

Quick utility that wraps input validation and
``next(ShuffleSplit().split(X, y))`` and application to input data
into a single call for splitting (and optionally subsampling) data in a
oneliner.

Read more in the :ref:`User Guide &lt;cross_validation&gt;`.

Parameters
----------
*arrays : sequence of indexables with same length / shape[0]
    Allowed inputs are lists, numpy arrays, scipy-sparse
    matrices or pandas dataframes.

test_size : float, int or None, optional (default=None)
    If float, should be between 0.0 and 1.0 and represent the proportion
    of the dataset to include in the test split. If int, represents the
    absolute number of test samples. If None, the value is set to the
    complement of the train size. If ``train_size`` is also None, it will
    be set to 0.25.

train_size : float, int, or None, (default=None)
    If float, should be between 0.0 and 1.0 and represent the
    proportion of the dataset to include in the train split. If
    int, represents the absolute number of train samples. If None,
    the value is automatically set to the complement of the test size.

random_state : int, RandomState instance or None, optional (default=None)
    If int, random_state is the seed used by the random number generator;
    If RandomState instance, random_state is the random number generator;
    If None, the random number generator is the RandomState instance used
    by `np.random`.

shuffle : boolean, optional (default=True)
    Whether or not to shuffle the data before splitting. If shuffle=False
    then stratify must be None.

stratify : array-like or None (default=None)
    If not None, data is split in a stratified fashion, using this as
    the class labels.

Returns
-------
splitting : list, length=2 * len(arrays)
    List containing train-test split of inputs.

    .. versionadded:: 0.16
        If the input is sparse, the output will be a
        ``scipy.sparse.csr_matrix``. Else, output type is the same as the
        input type.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; X, y = np.arange(10).reshape((5, 2)), range(5)
&gt;&gt;&gt; X
array([[0, 1],
       [2, 3],
       [4, 5],
       [6, 7],
       [8, 9]])
&gt;&gt;&gt; list(y)
[0, 1, 2, 3, 4]

&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.33, random_state=42)
...
&gt;&gt;&gt; X_train
array([[4, 5],
       [0, 1],
       [6, 7]])
&gt;&gt;&gt; y_train
[2, 0, 3]
&gt;&gt;&gt; X_test
array([[2, 3],
       [8, 9]])
&gt;&gt;&gt; y_test
[1, 4]

&gt;&gt;&gt; train_test_split(y, shuffle=False)
[[0, 1, 2], [3, 4]]
[0;31mFile:[0m      /Applications/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py
[0;31mType:[0m      function</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</span><br><span class="line">print(X_train.shape)</span><br><span class="line">print(y_train.shape)</span><br><span class="line">print(X_test.shape)</span><br><span class="line">print(y_test.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(1437, 64)
(1437,)
(360, 64)
(360,)</code></pre><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KNNClf = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KNNClf.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsClassifier(algorithm=&apos;auto&apos;, leaf_size=30, metric=&apos;minkowski&apos;,
                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,
                     weights=&apos;uniform&apos;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">res = KNNClf.predict(X_test)</span><br><span class="line">res</span><br></pre></td></tr></table></figure>




<pre><code>array([3, 4, 8, 5, 5, 7, 0, 3, 1, 4, 7, 5, 5, 8, 0, 7, 4, 7, 1, 7, 9, 4,
       4, 7, 6, 1, 2, 9, 1, 3, 3, 3, 7, 0, 7, 0, 2, 8, 9, 1, 1, 5, 4, 8,
       9, 0, 4, 9, 4, 9, 7, 2, 7, 3, 3, 4, 1, 9, 9, 9, 0, 4, 0, 6, 1, 0,
       0, 3, 6, 2, 3, 2, 8, 5, 9, 3, 1, 1, 6, 9, 8, 1, 2, 3, 2, 6, 8, 8,
       4, 6, 8, 6, 3, 9, 2, 8, 3, 6, 5, 7, 1, 7, 3, 8, 8, 8, 0, 0, 9, 1,
       9, 8, 5, 1, 1, 0, 1, 6, 5, 1, 7, 6, 5, 7, 7, 2, 2, 7, 3, 1, 9, 5,
       9, 5, 5, 3, 8, 4, 9, 5, 4, 6, 0, 5, 4, 8, 6, 1, 2, 8, 0, 9, 0, 9,
       7, 9, 7, 0, 2, 8, 2, 4, 0, 6, 2, 6, 7, 5, 6, 3, 8, 8, 0, 3, 2, 0,
       6, 1, 0, 6, 0, 5, 9, 3, 3, 0, 4, 0, 4, 2, 4, 9, 0, 6, 7, 4, 6, 5,
       9, 7, 2, 2, 3, 3, 0, 3, 9, 4, 9, 8, 5, 6, 9, 0, 1, 3, 5, 0, 5, 1,
       6, 4, 6, 6, 6, 7, 9, 1, 0, 7, 6, 6, 7, 8, 0, 3, 8, 5, 6, 8, 1, 3,
       0, 3, 6, 0, 3, 5, 6, 7, 0, 6, 9, 7, 0, 0, 2, 1, 6, 6, 9, 1, 6, 9,
       8, 7, 0, 2, 5, 1, 8, 6, 4, 3, 8, 2, 9, 2, 8, 4, 6, 4, 8, 9, 3, 1,
       1, 5, 0, 7, 8, 2, 3, 8, 4, 7, 7, 7, 7, 9, 4, 1, 7, 0, 2, 9, 1, 8,
       2, 4, 1, 0, 7, 5, 6, 0, 7, 1, 1, 5, 7, 1, 1, 6, 5, 6, 2, 2, 3, 9,
       7, 5, 3, 1, 5, 9, 9, 2, 5, 1, 6, 8, 2, 2, 4, 2, 1, 0, 6, 1, 2, 9,
       7, 5, 3, 5, 6, 1, 8, 1])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_test</span><br></pre></td></tr></table></figure>




<pre><code>array([3, 4, 8, 5, 5, 7, 0, 3, 1, 4, 7, 5, 5, 8, 0, 7, 4, 7, 1, 7, 9, 4,
       4, 7, 6, 1, 2, 9, 1, 3, 3, 3, 7, 0, 7, 0, 2, 8, 9, 1, 1, 5, 4, 8,
       9, 0, 4, 9, 4, 9, 7, 2, 7, 8, 3, 4, 1, 9, 9, 9, 0, 4, 0, 6, 1, 0,
       0, 3, 6, 2, 3, 2, 8, 5, 9, 3, 1, 1, 6, 9, 8, 1, 2, 3, 2, 6, 8, 8,
       4, 6, 8, 6, 3, 9, 2, 8, 3, 6, 5, 7, 1, 7, 9, 8, 8, 8, 0, 0, 9, 1,
       4, 8, 5, 1, 1, 0, 1, 6, 5, 1, 7, 6, 5, 7, 7, 2, 2, 7, 3, 1, 9, 5,
       9, 5, 5, 3, 8, 4, 9, 5, 4, 6, 0, 5, 4, 8, 6, 1, 2, 8, 0, 9, 0, 9,
       7, 9, 7, 0, 2, 8, 2, 4, 0, 6, 2, 6, 7, 5, 6, 3, 8, 8, 0, 3, 2, 0,
       6, 1, 0, 6, 0, 5, 9, 3, 3, 0, 4, 0, 4, 2, 4, 9, 0, 6, 7, 4, 6, 5,
       9, 7, 2, 2, 3, 3, 0, 3, 9, 4, 9, 8, 5, 6, 9, 0, 1, 3, 5, 0, 5, 1,
       6, 4, 6, 6, 6, 7, 9, 1, 0, 7, 6, 6, 7, 8, 0, 3, 8, 5, 6, 8, 1, 3,
       0, 3, 6, 0, 3, 5, 6, 7, 0, 6, 9, 7, 0, 0, 2, 1, 6, 6, 9, 1, 6, 9,
       8, 7, 0, 2, 5, 1, 8, 6, 4, 3, 8, 2, 9, 2, 8, 4, 6, 4, 8, 9, 3, 1,
       1, 5, 0, 7, 8, 2, 3, 8, 4, 7, 7, 7, 7, 7, 4, 1, 3, 0, 2, 9, 1, 8,
       2, 4, 1, 0, 7, 5, 6, 0, 7, 1, 1, 5, 7, 1, 1, 6, 5, 6, 2, 2, 3, 9,
       7, 5, 3, 1, 5, 9, 9, 2, 5, 1, 6, 8, 2, 2, 4, 2, 1, 0, 6, 1, 2, 9,
       7, 5, 3, 5, 6, 1, 8, 8])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num = sum(res == y_test)</span><br><span class="line">num</span><br></pre></td></tr></table></figure>




<pre><code>354</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'accuracy '</span>, num / len(y_test))</span><br></pre></td></tr></table></figure>

<pre><code>accuracy  0.9833333333333333</code></pre><h4 id="使用sklearn中封装的计算精确度的方法"><a href="#使用sklearn中封装的计算精确度的方法" class="headerlink" title="使用sklearn中封装的计算精确度的方法"></a>使用sklearn中封装的计算精确度的方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score <span class="keyword">as</span> accuracy</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">accuracy(res, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.9833333333333333</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://edlison.com/blog/2020/05/17/mlsec/KNN-%E6%89%8B%E5%86%99%E4%BD%93%E6%95%B0%E5%AD%97%E6%95%B0%E6%8D%AE%E9%9B%86/" data-id="ckaat5bo70000vaojc0re40jq" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-mlsec/KNN-鸢尾花数据集" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/17/mlsec/KNN-%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86/" class="article-date">
  <time datetime="2020-05-17T08:36:25.969Z" itemprop="datePublished">2020-05-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/17/mlsec/KNN-%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86/">mlsec/KNN-鸢尾花数据集</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="KNN-鸢尾花数据集"><a href="#KNN-鸢尾花数据集" class="headerlink" title="KNN-鸢尾花数据集"></a>KNN-鸢尾花数据集</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br></pre></td></tr></table></figure>

<h4 id="使用sklearn本地数据集中的鸢尾花数据集"><a href="#使用sklearn本地数据集中的鸢尾花数据集" class="headerlink" title="使用sklearn本地数据集中的鸢尾花数据集"></a>使用sklearn本地数据集中的鸢尾花数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris.keys()</span><br></pre></td></tr></table></figure>




<pre><code>dict_keys([&apos;data&apos;, &apos;target&apos;, &apos;target_names&apos;, &apos;DESCR&apos;, &apos;feature_names&apos;, &apos;filename&apos;])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = iris.data</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y = iris.target</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.shape</span><br></pre></td></tr></table></figure>




<pre><code>(150, 4)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y.shape</span><br></pre></td></tr></table></figure>




<pre><code>(150,)</code></pre><h1 id="手动分离测试数据"><a href="#手动分离测试数据" class="headerlink" title="手动分离测试数据"></a>手动分离测试数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shuffled_indexes = np.random.permutation(len(X))</span><br><span class="line">shuffled_indexes</span><br></pre></td></tr></table></figure>




<pre><code>array([ 47,  10, 144,  57, 135,  58,  36, 136,  73, 109,  64,  15, 104,
       143, 108,  83,  23, 126, 125, 131, 137,  22,  16,  29, 118,  31,
        33,  52,  32, 132,  45,  38,  78, 139,  30,  37,  61,  97, 122,
        56, 107,  66, 114,  87,  43,  76,  84,  79, 142,  70,  77,  42,
         7, 138, 141, 120, 129,  44,  24,  53, 116,  13,  91, 119,  93,
         6,  60,  50,  67,  20,  54,  71,  89,  68,  21, 133, 148,  81,
        25,  48, 130, 127,  28,  90,  82, 146, 100, 105,  80,  94,  14,
        55, 111, 106, 101, 103,  35,  99,   3,  26,  69, 124,  95,  96,
       140,  46,  19,  34,  75,  59,   1, 117, 121,  49, 110,   0, 115,
        72,   9,  18, 149,  40, 145,  92, 123,  51,   4,  11,  39,  85,
        62, 147, 102,  74,   2,  86,   8,  17,   5,  27, 112, 128,  12,
        65,  41, 134,  63,  88, 113,  98])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_ratio = <span class="number">0.2</span></span><br><span class="line">test_size = int(len(X) * test_ratio)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_indexes = shuffled_indexes[:test_size]</span><br><span class="line">train_indexes = shuffled_indexes[test_size:]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_train = X[train_indexes]</span><br><span class="line">Y_train = Y[train_indexes]</span><br><span class="line"></span><br><span class="line">X_test = X[test_indexes]</span><br><span class="line">Y_test = Y[test_indexes]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(X_train.shape);print(Y_train.shape);print(X_test.shape);print(Y_test.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(120, 4)
(120,)
(30, 4)
(30,)</code></pre><h1 id="使用sklearn分离"><a href="#使用sklearn分离" class="headerlink" title="使用sklearn分离"></a>使用sklearn分离</h1><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_test_split?</span><br></pre></td></tr></table></figure>


<pre><code>[0;31mSignature:[0m [0mtrain_test_split[0m[0;34m([0m[0;34m*[0m[0marrays[0m[0;34m,[0m [0;34m**[0m[0moptions[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;31mDocstring:[0m
Split arrays or matrices into random train and test subsets

Quick utility that wraps input validation and
``next(ShuffleSplit().split(X, y))`` and application to input data
into a single call for splitting (and optionally subsampling) data in a
oneliner.

Read more in the :ref:`User Guide &lt;cross_validation&gt;`.

Parameters
----------
*arrays : sequence of indexables with same length / shape[0]
    Allowed inputs are lists, numpy arrays, scipy-sparse
    matrices or pandas dataframes.

test_size : float, int or None, optional (default=None)
    If float, should be between 0.0 and 1.0 and represent the proportion
    of the dataset to include in the test split. If int, represents the
    absolute number of test samples. If None, the value is set to the
    complement of the train size. If ``train_size`` is also None, it will
    be set to 0.25.

train_size : float, int, or None, (default=None)
    If float, should be between 0.0 and 1.0 and represent the
    proportion of the dataset to include in the train split. If
    int, represents the absolute number of train samples. If None,
    the value is automatically set to the complement of the test size.

random_state : int, RandomState instance or None, optional (default=None)
    If int, random_state is the seed used by the random number generator;
    If RandomState instance, random_state is the random number generator;
    If None, the random number generator is the RandomState instance used
    by `np.random`.

shuffle : boolean, optional (default=True)
    Whether or not to shuffle the data before splitting. If shuffle=False
    then stratify must be None.

stratify : array-like or None (default=None)
    If not None, data is split in a stratified fashion, using this as
    the class labels.

Returns
-------
splitting : list, length=2 * len(arrays)
    List containing train-test split of inputs.

    .. versionadded:: 0.16
        If the input is sparse, the output will be a
        ``scipy.sparse.csr_matrix``. Else, output type is the same as the
        input type.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; X, y = np.arange(10).reshape((5, 2)), range(5)
&gt;&gt;&gt; X
array([[0, 1],
       [2, 3],
       [4, 5],
       [6, 7],
       [8, 9]])
&gt;&gt;&gt; list(y)
[0, 1, 2, 3, 4]

&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.33, random_state=42)
...
&gt;&gt;&gt; X_train
array([[4, 5],
       [0, 1],
       [6, 7]])
&gt;&gt;&gt; y_train
[2, 0, 3]
&gt;&gt;&gt; X_test
array([[2, 3],
       [8, 9]])
&gt;&gt;&gt; y_test
[1, 4]

&gt;&gt;&gt; train_test_split(y, shuffle=False)
[[0, 1, 2], [3, 4]]
[0;31mFile:[0m      /Applications/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py
[0;31mType:[0m      function</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(X_train.shape)</span><br><span class="line">print(Y_train.shape)</span><br><span class="line">print(X_test.shape)</span><br><span class="line">print(Y_test.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(120, 4)
(120,)
(30, 4)
(30,)</code></pre><h1 id="使用sklearn中的KNN分离器测试"><a href="#使用sklearn中的KNN分离器测试" class="headerlink" title="使用sklearn中的KNN分离器测试"></a>使用sklearn中的KNN分离器测试</h1><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">KNeighborsClassifier?</span><br></pre></td></tr></table></figure>


<pre><code>[0;31mInit signature:[0m
[0mKNeighborsClassifier[0m[0;34m([0m[0;34m[0m
[0;34m[0m    [0mn_neighbors[0m[0;34m=[0m[0;36m5[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mweights[0m[0;34m=[0m[0;34m&apos;uniform&apos;[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0malgorithm[0m[0;34m=[0m[0;34m&apos;auto&apos;[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mleaf_size[0m[0;34m=[0m[0;36m30[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mp[0m[0;34m=[0m[0;36m2[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mmetric[0m[0;34m=[0m[0;34m&apos;minkowski&apos;[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mmetric_params[0m[0;34m=[0m[0;32mNone[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mn_jobs[0m[0;34m=[0m[0;32mNone[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0;34m**[0m[0mkwargs[0m[0;34m,[0m[0;34m[0m
[0;34m[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;31mDocstring:[0m     
Classifier implementing the k-nearest neighbors vote.

Read more in the :ref:`User Guide &lt;classification&gt;`.

Parameters
----------
n_neighbors : int, optional (default = 5)
    Number of neighbors to use by default for :meth:`kneighbors` queries.

weights : str or callable, optional (default = &apos;uniform&apos;)
    weight function used in prediction.  Possible values:

    - &apos;uniform&apos; : uniform weights.  All points in each neighborhood
      are weighted equally.
    - &apos;distance&apos; : weight points by the inverse of their distance.
      in this case, closer neighbors of a query point will have a
      greater influence than neighbors which are further away.
    - [callable] : a user-defined function which accepts an
      array of distances, and returns an array of the same shape
      containing the weights.

algorithm : {&apos;auto&apos;, &apos;ball_tree&apos;, &apos;kd_tree&apos;, &apos;brute&apos;}, optional
    Algorithm used to compute the nearest neighbors:

    - &apos;ball_tree&apos; will use :class:`BallTree`
    - &apos;kd_tree&apos; will use :class:`KDTree`
    - &apos;brute&apos; will use a brute-force search.
    - &apos;auto&apos; will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, optional (default = 30)
    Leaf size passed to BallTree or KDTree.  This can affect the
    speed of the construction and query, as well as the memory
    required to store the tree.  The optimal value depends on the
    nature of the problem.

p : integer, optional (default = 2)
    Power parameter for the Minkowski metric. When p = 1, this is
    equivalent to using manhattan_distance (l1), and euclidean_distance
    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

metric : string or callable, default &apos;minkowski&apos;
    the distance metric to use for the tree.  The default metric is
    minkowski, and with p=2 is equivalent to the standard Euclidean
    metric. See the documentation of the DistanceMetric class for a
    list of available metrics.
    If metric is &quot;precomputed&quot;, X is assumed to be a distance matrix and
    must be square during fit. X may be a :term:`Glossary &lt;sparse graph&gt;`,
    in which case only &quot;nonzero&quot; elements may be considered neighbors.

metric_params : dict, optional (default = None)
    Additional keyword arguments for the metric function.

n_jobs : int or None, optional (default=None)
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details.
    Doesn&apos;t affect :meth:`fit` method.

Attributes
----------
classes_ : array of shape (n_classes,)
    Class labels known to the classifier

effective_metric_ : string or callble
    The distance metric used. It will be same as the `metric` parameter
    or a synonym of it, e.g. &apos;euclidean&apos; if the `metric` parameter set to
    &apos;minkowski&apos; and `p` parameter set to 2.

effective_metric_params_ : dict
    Additional keyword arguments for the metric function. For most metrics
    will be same with `metric_params` parameter, but may also contain the
    `p` parameter value if the `effective_metric_` attribute is set to
    &apos;minkowski&apos;.

outputs_2d_ : bool
    False when `y`&apos;s shape is (n_samples, ) or (n_samples, 1) during fit
    otherwise True.

Examples
--------
&gt;&gt;&gt; X = [[0], [1], [2], [3]]
&gt;&gt;&gt; y = [0, 0, 1, 1]
&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier
&gt;&gt;&gt; neigh = KNeighborsClassifier(n_neighbors=3)
&gt;&gt;&gt; neigh.fit(X, y)
KNeighborsClassifier(...)
&gt;&gt;&gt; print(neigh.predict([[1.1]]))
[0]
&gt;&gt;&gt; print(neigh.predict_proba([[0.9]]))
[[0.66666667 0.33333333]]

See also
--------
RadiusNeighborsClassifier
KNeighborsRegressor
RadiusNeighborsRegressor
NearestNeighbors

Notes
-----
See :ref:`Nearest Neighbors &lt;neighbors&gt;` in the online documentation
for a discussion of the choice of ``algorithm`` and ``leaf_size``.

.. warning::

   Regarding the Nearest Neighbors algorithms, if it is found that two
   neighbors, neighbor `k+1` and `k`, have identical distances
   but different labels, the results will depend on the ordering of the
   training data.

https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm
[0;31mFile:[0m           /Applications/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/_classification.py
[0;31mType:[0m           ABCMeta
[0;31mSubclasses:[0m     </code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">KNNClf = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">KNNClf.fit(X_train, Y_train)</span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsClassifier(algorithm=&apos;auto&apos;, leaf_size=30, metric=&apos;minkowski&apos;,
                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,
                     weights=&apos;uniform&apos;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">res = KNNClf.predict(X_test)</span><br><span class="line">res</span><br></pre></td></tr></table></figure>




<pre><code>array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,
       1, 0, 2, 1, 0, 0, 1, 2])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y_test</span><br></pre></td></tr></table></figure>




<pre><code>array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,
       1, 0, 2, 1, 0, 0, 1, 2])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">acc = sum(res == Y_test)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'accuracy '</span>, acc / len(Y_test))</span><br></pre></td></tr></table></figure>

<pre><code>accuracy  1.0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://edlison.com/blog/2020/05/17/mlsec/KNN-%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86/" data-id="ckaat5boe0002vaojg8iybnjo" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-mlsec/KNN-手动实现" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/17/mlsec/KNN-%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0/" class="article-date">
  <time datetime="2020-05-17T08:34:34.000Z" itemprop="datePublished">2020-05-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/17/mlsec/KNN-%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0/">mlsec/KNN-手动实现</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="手动实现KNN"><a href="#手动实现KNN" class="headerlink" title="手动实现KNN"></a>手动实现KNN</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">raw_data_x = [[<span class="number">3.393533211</span>, <span class="number">2.331273381</span>],</span><br><span class="line">              [<span class="number">3.110073483</span>, <span class="number">1.781539638</span>],</span><br><span class="line">              [<span class="number">1.343808831</span>, <span class="number">3.368360954</span>],</span><br><span class="line">              [<span class="number">3.582294042</span>, <span class="number">4.679179110</span>],</span><br><span class="line">              [<span class="number">2.280362439</span>, <span class="number">2.866990263</span>],</span><br><span class="line">              [<span class="number">7.423436942</span>, <span class="number">4.696522875</span>],</span><br><span class="line">              [<span class="number">5.745051997</span>, <span class="number">3.533989803</span>],</span><br><span class="line">              [<span class="number">9.172168622</span>, <span class="number">2.511101045</span>],</span><br><span class="line">              [<span class="number">7.792783481</span>, <span class="number">3.424088941</span>],</span><br><span class="line">              [<span class="number">7.939820817</span>, <span class="number">0.791637231</span>]</span><br><span class="line">             ]</span><br><span class="line">raw_data_y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train = np.array(raw_data_x)</span><br><span class="line">y_train = np.array(raw_data_y)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_train</span><br></pre></td></tr></table></figure>




<pre><code>array([[3.39353321, 2.33127338],
       [3.11007348, 1.78153964],
       [1.34380883, 3.36836095],
       [3.58229404, 4.67917911],
       [2.28036244, 2.86699026],
       [7.42343694, 4.69652288],
       [5.745052  , 3.5339898 ],
       [9.17216862, 2.51110105],
       [7.79278348, 3.42408894],
       [7.93982082, 0.79163723]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_train==<span class="number">1</span></span><br></pre></td></tr></table></figure>




<pre><code>array([False, False, False, False, False,  True,  True,  True,  True,
        True])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(x_train[y_train==<span class="number">1</span>, <span class="number">0</span>], x_train[y_train==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">'r'</span>, label=<span class="string">'1'</span>)</span><br><span class="line">plt.scatter(x_train[y_train==<span class="number">0</span>, <span class="number">0</span>], x_train[y_train==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">'g'</span>, label=<span class="string">'0'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.legend.Legend at 0x122311ad0&gt;</code></pre><p><img src="data/output_6_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">8.093607318</span>, <span class="number">3.365731514</span>])</span><br><span class="line"></span><br><span class="line">plt.scatter(x_train[y_train==<span class="number">1</span>, <span class="number">0</span>], x_train[y_train==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">'r'</span>, label=<span class="string">'1'</span>)</span><br><span class="line">plt.scatter(x_train[y_train==<span class="number">0</span>, <span class="number">0</span>], x_train[y_train==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">'g'</span>, label=<span class="string">'0'</span>)</span><br><span class="line">plt.scatter(x[<span class="number">0</span>], x[<span class="number">1</span>], color=<span class="string">'b'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="data/output_7_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line">distance = []</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> x_train:</span><br><span class="line">    d = math.sqrt(np.sum((each - x) ** <span class="number">2</span>))</span><br><span class="line">    distance.append(d)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distance</span><br></pre></td></tr></table></figure>




<pre><code>[4.812566907609877,
 5.229270827235305,
 6.749798999160064,
 4.6986266144110695,
 5.83460014556857,
 1.4900114024329525,
 2.354574897431513,
 1.3761132675144652,
 0.3064319992975,
 2.5786840957478887]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">distances = [math.sqrt(np.sum((each - x) ** <span class="number">2</span>)) <span class="keyword">for</span> each <span class="keyword">in</span> x_train]</span><br><span class="line">distances</span><br></pre></td></tr></table></figure>




<pre><code>[4.812566907609877,
 5.229270827235305,
 6.749798999160064,
 4.6986266144110695,
 5.83460014556857,
 1.4900114024329525,
 2.354574897431513,
 1.3761132675144652,
 0.3064319992975,
 2.5786840957478887]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nearest = np.argsort(distances)</span><br><span class="line">nearest</span><br></pre></td></tr></table></figure>




<pre><code>array([8, 7, 5, 6, 9, 3, 0, 1, 4, 2])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">k = <span class="number">6</span></span><br><span class="line">topK_y = [y_train[i] <span class="keyword">for</span> i <span class="keyword">in</span> nearest[:k]]</span><br><span class="line">topK_y</span><br></pre></td></tr></table></figure>




<pre><code>[1, 1, 1, 1, 1, 0]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line">votes = collections.Counter(topK_y)</span><br><span class="line">votes</span><br></pre></td></tr></table></figure>




<pre><code>Counter({1: 5, 0: 1})</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">votes.most_common(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>




<pre><code>[(1, 5)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predict_y = votes.most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">predict_y</span><br></pre></td></tr></table></figure>




<pre><code>1</code></pre><h1 id="scikit-learn实现KNN"><a href="#scikit-learn实现KNN" class="headerlink" title="scikit-learn实现KNN"></a>scikit-learn实现KNN</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">raw_data_x = [[<span class="number">3.393533211</span>, <span class="number">2.331273381</span>],</span><br><span class="line">              [<span class="number">3.110073483</span>, <span class="number">1.781539638</span>],</span><br><span class="line">              [<span class="number">1.343808831</span>, <span class="number">3.368360954</span>],</span><br><span class="line">              [<span class="number">3.582294042</span>, <span class="number">4.679179110</span>],</span><br><span class="line">              [<span class="number">2.280362439</span>, <span class="number">2.866990263</span>],</span><br><span class="line">              [<span class="number">7.423436942</span>, <span class="number">4.696522875</span>],</span><br><span class="line">              [<span class="number">5.745051997</span>, <span class="number">3.533989803</span>],</span><br><span class="line">              [<span class="number">9.172168622</span>, <span class="number">2.511101045</span>],</span><br><span class="line">              [<span class="number">7.792783481</span>, <span class="number">3.424088941</span>],</span><br><span class="line">              [<span class="number">7.939820817</span>, <span class="number">0.791637231</span>]</span><br><span class="line">             ]</span><br><span class="line">raw_data_y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">x_train = np.array(raw_data_x)</span><br><span class="line">y_train = np.array(raw_data_y)</span><br><span class="line"></span><br><span class="line">target = np.array([<span class="number">8.093607318</span>, <span class="number">3.365731514</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KNN_classifier = KNeighborsClassifier(n_neighbors=<span class="number">6</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KNN_classifier.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsClassifier(algorithm=&apos;auto&apos;, leaf_size=30, metric=&apos;minkowski&apos;,
                     metric_params=None, n_jobs=None, n_neighbors=6, p=2,
                     weights=&apos;uniform&apos;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">target = x.reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">print(target)</span><br></pre></td></tr></table></figure>

<pre><code>[[8.09360732 3.36573151]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KNN_classifier.predict(target)</span><br></pre></td></tr></table></figure>




<pre><code>array([1])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">res = KNN_classifier.predict(target)</span><br><span class="line">res[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>




<pre><code>1</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://edlison.com/blog/2020/05/17/mlsec/KNN-%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0/" data-id="ckaat5bof0003vaojca7q50d5" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-mlsec/Python-数据探索之可视化分析" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/17/mlsec/Python-%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E4%B9%8B%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90/" class="article-date">
  <time datetime="2020-05-17T08:28:04.000Z" itemprop="datePublished">2020-05-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/17/mlsec/Python-%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E4%B9%8B%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90/">mlsec/Python-数据探索之可视化分析</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Python-数据可视化分析"><a href="#Python-数据可视化分析" class="headerlink" title="Python 数据可视化分析"></a>Python 数据可视化分析</h2><hr>
<h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>在机器学习领域中，可视化是十分重要的。在开始一项新任务时，通过可视化手段探索数据能更好地帮助人们把握数据的要点。在分析模型表现和模型报告的结果时，可视化能使分析显得更加生动鲜明。有时候，为了理解复杂的模型，我们还可以将高维空间映射为视觉上更直观的二维或三维图形。</p>
<p>总而言之，可视化是一个相对快捷的从数据中挖掘信息的手段。本文将使用 Pandas、Matplotlib、seaborn 等流行的库，带你上手可视化。</p>
<h4 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h4><ul>
<li>单变量可视化的常用方法</li>
<li>多变量可视化的常用方法</li>
<li>t-SNE</li>
</ul>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>首先使用 <code>import</code> 载入相关依赖。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.set()</span><br></pre></td></tr></table></figure>

<p>在第一篇文章中，我们使用的是某电信运营商的客户离网数据集，本次实验仍旧使用这个数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'./data/telecom_churn.csv'</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>State</th>
      <th>Account length</th>
      <th>Area code</th>
      <th>International plan</th>
      <th>Voice mail plan</th>
      <th>Number vmail messages</th>
      <th>Total day minutes</th>
      <th>Total day calls</th>
      <th>Total day charge</th>
      <th>Total eve minutes</th>
      <th>Total eve calls</th>
      <th>Total eve charge</th>
      <th>Total night minutes</th>
      <th>Total night calls</th>
      <th>Total night charge</th>
      <th>Total intl minutes</th>
      <th>Total intl calls</th>
      <th>Total intl charge</th>
      <th>Customer service calls</th>
      <th>Churn</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>KS</td>
      <td>128</td>
      <td>415</td>
      <td>No</td>
      <td>Yes</td>
      <td>25</td>
      <td>265.1</td>
      <td>110</td>
      <td>45.07</td>
      <td>197.4</td>
      <td>99</td>
      <td>16.78</td>
      <td>244.7</td>
      <td>91</td>
      <td>11.01</td>
      <td>10.0</td>
      <td>3</td>
      <td>2.70</td>
      <td>1</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>OH</td>
      <td>107</td>
      <td>415</td>
      <td>No</td>
      <td>Yes</td>
      <td>26</td>
      <td>161.6</td>
      <td>123</td>
      <td>27.47</td>
      <td>195.5</td>
      <td>103</td>
      <td>16.62</td>
      <td>254.4</td>
      <td>103</td>
      <td>11.45</td>
      <td>13.7</td>
      <td>3</td>
      <td>3.70</td>
      <td>1</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NJ</td>
      <td>137</td>
      <td>415</td>
      <td>No</td>
      <td>No</td>
      <td>0</td>
      <td>243.4</td>
      <td>114</td>
      <td>41.38</td>
      <td>121.2</td>
      <td>110</td>
      <td>10.30</td>
      <td>162.6</td>
      <td>104</td>
      <td>7.32</td>
      <td>12.2</td>
      <td>5</td>
      <td>3.29</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>OH</td>
      <td>84</td>
      <td>408</td>
      <td>Yes</td>
      <td>No</td>
      <td>0</td>
      <td>299.4</td>
      <td>71</td>
      <td>50.90</td>
      <td>61.9</td>
      <td>88</td>
      <td>5.26</td>
      <td>196.9</td>
      <td>89</td>
      <td>8.86</td>
      <td>6.6</td>
      <td>7</td>
      <td>1.78</td>
      <td>2</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>OK</td>
      <td>75</td>
      <td>415</td>
      <td>Yes</td>
      <td>No</td>
      <td>0</td>
      <td>166.7</td>
      <td>113</td>
      <td>28.34</td>
      <td>148.3</td>
      <td>122</td>
      <td>12.61</td>
      <td>186.9</td>
      <td>121</td>
      <td>8.41</td>
      <td>10.1</td>
      <td>3</td>
      <td>2.73</td>
      <td>3</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>



<p>最后一个数据列 Churn 离网率 是我们的目标特征，它是布尔变量，其中 True 表示公司最终丢失了此客户，False 表示客户被保留。稍后，将构建基于其他特征预测 Churn 特征的模型。 </p>
<h3 id="单变量可视化"><a href="#单变量可视化" class="headerlink" title="单变量可视化"></a>单变量可视化</h3><p>单变量（univariate）分析一次只关注一个变量。当我们独立地分析一个特征时，通常最关心的是该特征值的分布情况。下面考虑不同统计类型的变量，以及相应的可视化工具。</p>
<h4 id="数量特征"><a href="#数量特征" class="headerlink" title="数量特征"></a>数量特征</h4><p>数量特征（quantitative feature）的值为有序数值。这些值可能是离散的，例如整数，也可能是连续的，例如实数。</p>
<h4 id="直方图和密度图"><a href="#直方图和密度图" class="headerlink" title="直方图和密度图"></a>直方图和密度图</h4><p>直方图依照相等的间隔将值分组为柱，它的形状可能包含了数据分布的一些信息，如高斯分布、指数分布等。当分布总体呈现规律性，但有个别异常值时，你可以通过直方图辨认出来。当你使用的机器学习方法预设了某一特定分布类型（通常是高斯分布）时，知道特征值的分布是非常重要的。</p>
<p>最简单的查看数值变量分布的方法是使用 DataFrame 的 <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.hist.html" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> <code>hist()</code></i></a> 方法绘制直方图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">features = [<span class="string">'Total day minutes'</span>, <span class="string">'Total intl calls'</span>]</span><br><span class="line">df[features].hist(figsize = (<span class="number">10</span>, <span class="number">4</span>))</span><br></pre></td></tr></table></figure>




<pre><code>array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x12e3076d0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x12f4cbe90&gt;]],
      dtype=object)</code></pre><p><img src="data/output_21_1.png" alt="png"></p>
<p>上图表明，变量 Total day minutes 每日通话时长 呈高斯分布，而 Total intl calls 总国际呼叫数 显著右倾（它右侧的尾巴更长）。</p>
<p>密度图（density plots），也叫核密度图（ <a href="https://en.wikipedia.org/wiki/Kernel_density_estimation" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> kernel density estimate</i></a>，KDE）是理解数值变量分布的另一个方法。它可以看成是直方图平滑（ <a href="https://en.wikipedia.org/wiki/Kernel_smoother" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> smoothed</i></a> ）的版本。相比直方图，它的主要优势是不依赖于柱的尺寸，更加清晰。</p>
<p>让我们为上面两个变量创建密度图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[features].plot(kind=<span class="string">'density'</span>, subplots=<span class="literal">True</span>, layout=(<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">                 sharex=<span class="literal">False</span>, figsize=(<span class="number">10</span>, <span class="number">4</span>), legend=<span class="literal">False</span>, title=features)</span><br></pre></td></tr></table></figure>




<pre><code>array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x133bcc050&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1343f1ad0&gt;]],
      dtype=object)</code></pre><p><img src="data/output_25_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.distplot(df[<span class="string">'Total day calls'</span>])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x12e4f8810&gt;</code></pre><p><img src="data/output_26_1.png" alt="png"></p>
<p>当然，还可以使用 seaborn 的 <a href="https://seaborn.pydata.org/generated/seaborn.distplot.html" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> <code>distplot()</code></i></a> 方法观测数值变量的分布。例如，Total day minutes 每日通话时长 的分布。默认情况下，该方法将同时显示直方图和密度图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.distplot(df[<span class="string">'Total intl calls'</span>])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x12e5134d0&gt;</code></pre><p><img src="data/output_28_1.png" alt="png"></p>
<p>上图中直方图的柱形高度已进行归一化处理，表示的是密度而不是样本数。</p>
<h4 id="箱型图"><a href="#箱型图" class="headerlink" title="箱型图"></a>箱型图</h4><p>箱形图的主要组成部分是箱子（box），须（whisker）和一些单独的数据点（离群值），分别简单介绍如下：</p>
<ul>
<li>箱子显示了分布的四分位距，它的长度由 $25th , （\text{Q1，下四分位数}）$ 和 $75th , （\text{Q3，上四分位数}）$ 决定，箱中的水平线表示中位数  （$50%$）。</li>
<li>须是从箱子处延伸出来的线，它们表示数据点的总体散布，具体而言，是位于区间 $（\text{Q1} - 1.5 \cdot \text{IQR}, \text{Q3} + 1.5 \cdot \text{IQR}）$的数据点，其中 $\text{IQR} = \text{Q3} - \text{Q1}$，也就是四分位距。</li>
<li>离群值是须之外的数据点，它们作为单独的数据点，沿着中轴绘制。</li>
</ul>
<p>使用 seaborn 的 <code>boxplot()</code> 方法绘制箱形图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.boxplot(df[<span class="string">'Total intl calls'</span>])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x12e6e1750&gt;</code></pre><p><img src="data/output_34_1.png" alt="png"></p>
<p>上图表明，在该数据集中，大量的国际呼叫是相当少见的。</p>
<h4 id="提琴形图"><a href="#提琴形图" class="headerlink" title="提琴形图"></a>提琴形图</h4><p>我们最后考虑的分布图形是提琴形图（violin plot）。提琴形图和箱形图的区别是，提琴形图聚焦于平滑后的整体分布，而箱形图显示了单独样本的特定统计数据。</p>
<p>使用 <code>violinplot()</code> 方法绘制提琴形图。下图左侧是箱形图，右侧是提琴形图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">_, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, sharey=<span class="literal">True</span>, figsize=(<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.boxplot(df[<span class="string">'Total intl calls'</span>], ax=ax[<span class="number">0</span>])</span><br><span class="line">sns.violinplot(df[<span class="string">'Total intl calls'</span>], ax=ax[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1380219d0&gt;</code></pre><p><img src="data/output_39_1.png" alt="png"></p>
<h4 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h4><p>除图形工具外，还可以使用 DataFrame 的 <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> <code>describe()</code></i></a> 方法来获取分布的精确数值统计。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[features].describe()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Total day minutes</th>
      <th>Total intl calls</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>3333.000000</td>
      <td>3333.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>179.775098</td>
      <td>4.479448</td>
    </tr>
    <tr>
      <th>std</th>
      <td>54.467389</td>
      <td>2.461214</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>143.700000</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>179.400000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>216.400000</td>
      <td>6.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>350.800000</td>
      <td>20.000000</td>
    </tr>
  </tbody>
</table>
</div>



<p><code>describe()</code> 的输出基本上是自解释性的，25%，50% 和 75% 是相应的百分数 <a href="https://en.wikipedia.org/wiki/Percentile" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> percentiles</i></a>。</p>
<h4 id="类别特征和二元特征"><a href="#类别特征和二元特征" class="headerlink" title="类别特征和二元特征"></a>类别特征和二元特征</h4><p>类别特征（categorical features take）反映了样本的某个定性属性，它具有固定数目的值，每个值将一个观测数据分配到相应的组，这些组称为类别（category）。如果类别变量的值具有顺序，称为有序（ordinal）类别变量。</p>
<p>二元（binary）特征是类别特征的特例，其可能值有 2 个。</p>
<h4 id="频率表"><a href="#频率表" class="headerlink" title="频率表"></a>频率表</h4><p>让我们查看一下目标变量 Churn 离网率 的分布情况。首先，使用 <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> <code>value_counts()</code></i></a> 方法得到一张频率表。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'Churn'</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>False    2850
True      483
Name: Churn, dtype: int64</code></pre><p>上表显示，该数据集的 Churn 有 2850 个属于 False（Churn==0），有 483 个属于 True（Churn==1），数据集中忠实客户（Churn==0）和不忠实客户（Churn==1）的比例并不相等。我们将在以后的文章中看到，这种数据不平衡的情况会导致建立的分类模型存在一定的问题。在这种情况下，构建分类模型可能需要加重对「少数数据（在这里是 Churn==1）分类错误」这一情况的惩罚。</p>
<h4 id="条形图"><a href="#条形图" class="headerlink" title="条形图"></a>条形图</h4><p>频率表的图形化表示是条形图。创建条形图最简单的方法是使用 seaborn 的 <a href="https://seaborn.pydata.org/generated/seaborn.countplot.html" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> <code>countplot()</code></i></a> 函数。让我们来画出两个分类变量的分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=[<span class="number">10</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">sns.countplot(df[<span class="string">'Churn'</span>], ax=ax[<span class="number">0</span>])</span><br><span class="line">sns.countplot(df[<span class="string">'Customer service calls'</span>], ax=ax[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1382242d0&gt;</code></pre><p><img src="data/output_53_1.png" alt="png"></p>
<p>条形图和直方图的区别如下：</p>
<ul>
<li>直方图适合查看数值变量的分布，而条形图用于查看类别特征。</li>
<li>直方图的 X 轴是数值；条形图的 X 轴可能是任何类型，如数字、字符串、布尔值。</li>
<li>直方图的 X 轴是一个笛卡尔坐标轴；条形图的顺序则没有事先定义。</li>
</ul>
<p>上左图清晰地表明了目标变量的失衡性。上右图则表明大部分客户最多打了 2-3 个客服电话就解决了他们的问题。不过，既然想要预测少数数据的分类（Churn==1），我们可能对少数不满意的客户的表现更感兴趣。所以让我们尝试一下更有趣的可视化方法：多变量可视化，看能否对预测有所帮助。</p>
<h3 id="多变量可视化"><a href="#多变量可视化" class="headerlink" title="多变量可视化"></a>多变量可视化</h3><p>多变量（multivariate）图形可以在单张图像中查看两个以上变量的联系，和单变量图形一样，可视化的类型取决于将要分析的变量的类型。</p>
<p>先来看看数量变量之间的相互作用。</p>
<h4 id="相关矩阵"><a href="#相关矩阵" class="headerlink" title="相关矩阵"></a>相关矩阵</h4><p>相关矩阵可揭示数据集中的数值变量的相关性。这一信息很重要，因为有一些机器学习算法（比如，线性回归和逻辑回归）不能很好地处理高度相关的输入变量。</p>
<p>首先，我们使用 DataFrame 的 <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> <code>corr()</code></i></a> 方法计算出每对特征间的相关性。接着，我们将所得的相关矩阵（correlation matrix）传给 seaborn 的 <a href="https://seaborn.pydata.org/generated/seaborn.heatmap.html" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> <code>heatmap()</code></i></a>方法，该方法根据提供的数值，渲染出一个基于色彩编码的矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">numerical = list(set(df.columns) - set([<span class="string">'State'</span>, <span class="string">'International plan'</span>, <span class="string">'Voice mail plan'</span>, <span class="string">'Area code'</span>, <span class="string">'Churn'</span>, <span class="string">'Customer service calls'</span>]))</span><br><span class="line"></span><br><span class="line">corr = df[numerical].corr()</span><br><span class="line">sns.heatmap(corr)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1388bad50&gt;</code></pre><p><img src="data/output_63_1.png" alt="png"></p>
<p>上图中，Total day charge 日话费总额 是直接基于 Total day minutes 电话的分钟数 计算得到，它被称为因变量。除了 Total day charege 外，还有 3 个因变量：Total eve charge，Total night charge，Total intl charge。这 4 个因变量并不贡献任何额外信息，我们直接去除。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">numerical = list(set(numerical) - set([<span class="string">'Total day charge'</span>, <span class="string">'Total eve charge'</span>, <span class="string">'Total night charge'</span>, <span class="string">'Total intl charge'</span>]))</span><br><span class="line"></span><br><span class="line">corr = df[numerical].corr()</span><br><span class="line">sns.heatmap(corr)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1396822d0&gt;</code></pre><p><img src="data/output_65_1.png" alt="png"></p>
<h4 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h4><p>散点图（scatter plot）将两个数值变量的值显示为二维空间中的笛卡尔坐标（Cartesian coordinate）。通过 matplotlib 库的 <a href="https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.scatter.html" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> <code>scatter()</code></i></a> 方法可以绘制散点图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(df[<span class="string">'Total day minutes'</span>], df[<span class="string">'Total night minutes'</span>])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.collections.PathCollection at 0x139a17c10&gt;</code></pre><p><img src="data/output_67_1.png" alt="png"></p>
<p>我们得到了两个正态分布变量的散点图，看起来这两个变量并不相关，因为上图的形状和轴是对齐的。</p>
<p>seaborn 库的 <a href="https://seaborn.pydata.org/generated/seaborn.jointplot.html" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> <code>jointplot()</code></i></a> 方法在绘制散点图的同时会绘制两张直方图，某些情形下它们可能会更有用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.jointplot(df[<span class="string">'Total day minutes'</span>], df[<span class="string">'Total night minutes'</span>])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.JointGrid at 0x139888cd0&gt;</code></pre><p><img src="data/output_70_1.png" alt="png"></p>
<p><code>jointplot()</code> 方法还可以绘制平滑过的散点直方图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.jointplot(df[<span class="string">'Total day minutes'</span>], df[<span class="string">'Total night minutes'</span>], kind=<span class="string">'kde'</span>, color=<span class="string">'g'</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.JointGrid at 0x139dc1890&gt;</code></pre><p><img src="data/output_72_1.png" alt="png"></p>
<p>上图基本上就是之前讨论过的核密度图的双变量版本。</p>
<h4 id="散点图矩阵"><a href="#散点图矩阵" class="headerlink" title="散点图矩阵"></a>散点图矩阵</h4><p>在某些情形下，我们可能想要绘制如下所示的散点图矩阵（scatterplot matrix）。它的对角线包含变量的分布，并且每对变量的散点图填充了矩阵的其余部分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># %config InlineBackend.figure_format = 'png'</span></span><br><span class="line">sns.pairplot(df[numerical])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.PairGrid at 0x139cb5810&gt;</code></pre><p><img src="data/output_76_1.png" alt="png"></p>
<h4 id="数量和类别"><a href="#数量和类别" class="headerlink" title="数量和类别"></a>数量和类别</h4><p>为了让图形更有趣一点，可以尝试从数值和类别特征的相互作用中得到预测 Churn 的新信息，更具体地，让我们看看输入变量和目标变量 Churn 的关系。使用 <a href="https://seaborn.pydata.org/generated/seaborn.lmplot.html" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> <code>lmplot()</code></i></a> 方法的 hue 参数来指定感兴趣的类别特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.lmplot(<span class="string">'Total day minutes'</span>, <span class="string">'Total night minutes'</span>, data=df, hue=<span class="string">'Churn'</span>, fit_reg=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x13e7df950&gt;</code></pre><p><img src="data/output_79_2.png" alt="png"></p>
<p>看起来不忠实客户偏向右上角，也就是倾向于在白天和夜间打更多电话的客户。当然，这不是非常明显，我们也不会基于这一图形下任何确定性的结论。</p>
<p>现在，创建箱形图，以可视化忠实客户（Churn=0）和离网客户（Churn=1）这两个互斥分组中数值变量分布的统计数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">numerical.append(<span class="string">'Customer service calls'</span>)</span><br><span class="line">print(numerical)</span><br><span class="line">fig, axes = plt.subplots(<span class="number">3</span>, <span class="number">4</span>, figsize=[<span class="number">10</span>, <span class="number">7</span>])</span><br><span class="line"><span class="keyword">for</span> index, feat <span class="keyword">in</span> enumerate(numerical):</span><br><span class="line">    ax = axes[int(index / <span class="number">4</span>), index % <span class="number">4</span>]</span><br><span class="line">    sns.boxplot(df[<span class="string">'Churn'</span>], df[feat], ax=ax)</span><br><span class="line">    ax.set_xlabel(<span class="string">''</span>)</span><br><span class="line">    ax.set_ylabel(feat)</span><br><span class="line">fig.tight_layout()</span><br></pre></td></tr></table></figure>

<pre><code>[&apos;Total day minutes&apos;, &apos;Total night minutes&apos;, &apos;Number vmail messages&apos;, &apos;Total eve calls&apos;, &apos;Account length&apos;, &apos;Total intl calls&apos;, &apos;Total eve minutes&apos;, &apos;Total night calls&apos;, &apos;Total day calls&apos;, &apos;Total intl minutes&apos;, &apos;Customer service calls&apos;, &apos;Customer service calls&apos;, &apos;Customer service calls&apos;, &apos;Customer service calls&apos;, &apos;Customer service calls&apos;, &apos;Customer service calls&apos;, &apos;Customer service calls&apos;, &apos;Customer service calls&apos;]



---------------------------------------------------------------------------

IndexError                                Traceback (most recent call last)

&lt;ipython-input-47-539701aff8ff&gt; in &lt;module&gt;
      3 fig, axes = plt.subplots(3, 4, figsize=[10, 7])
      4 for index, feat in enumerate(numerical):
----&gt; 5     ax = axes[int(index / 4), index % 4]
      6     sns.boxplot(df[&apos;Churn&apos;], df[feat], ax=ax)
      7     ax.set_xlabel(&apos;&apos;)


IndexError: index 3 is out of bounds for axis 0 with size 3</code></pre><p><img src="data/output_82_2.png" alt="png"></p>
<p>上面的图表表明，两组之间分歧最大的分布是这三个变量：Total day minutes 日通话分钟数、Customer service calls 客服呼叫数、Number vmail messages 语音邮件数。在后续的课程中，我们将学习如何使用随机森林（Random Forest）或梯度提升（Gradient Boosting）来判定特征对分类的重要性，届时可以清晰地看到，前两个特征对于离网预测模型而言确实非常重要。</p>
<p>创建箱型图和提琴形图，查看忠实客户和不忠实客户的日通话分钟数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">_, axes = plt.subplots(<span class="number">2</span>, <span class="number">2</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>, figsize=[<span class="number">10</span>, <span class="number">8</span>])</span><br><span class="line">sns.boxplot(x=<span class="string">'Churn'</span>, y=<span class="string">'Total day minutes'</span>, data=df, ax=axes[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">sns.violinplot(x=<span class="string">'Churn'</span>, y=<span class="string">"Total day minutes"</span>, data=df, ax=axes[<span class="number">0</span>][<span class="number">1</span>])</span><br><span class="line">sns.boxplot(x=<span class="string">'Churn'</span>, y=<span class="string">'Total night minutes'</span>, data=df, ax=axes[<span class="number">1</span>][<span class="number">0</span>])</span><br><span class="line">sns.violinplot(x=<span class="string">'Churn'</span>, y=<span class="string">"Total night minutes"</span>, data=df, ax=axes[<span class="number">1</span>][<span class="number">1</span>])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x140f70290&gt;</code></pre><p><img src="data/output_85_1.png" alt="png"></p>
<p>上图表明，不忠实客户倾向于打更多的电话。</p>
<p>我们还可以发现一个有趣的信息：平均而言，离网客户是通讯服务更活跃的用户。或许是他们对话费不满意，所以预防离网的一个可能措施是降低通话费。当然，公司需要进行额外的经济分析，以查明这样做是否真的有利。</p>
<p>当想要一次性分析两个类别维度下的数量变量时，可以用 seaborn 库的 <a href="https://seaborn.pydata.org/generated/seaborn.factorplot.html" target="_blank" rel="noopener"><i class="fa fa-external-link-square" aria-hidden="true"> <code>catplot()</code></i></a> 函数。例如，在同一图形中可视化 Total day minutes 日通话分钟数 和两个类别变量（Churn 和 Customer service calls）的相互作用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">'Churn'</span>, y=<span class="string">'Total day minutes'</span>, col=<span class="string">'Customer service calls'</span>,</span><br><span class="line">          data=df[df[<span class="string">'Customer service calls'</span>] &lt; <span class="number">8</span>], kind=<span class="string">'box'</span>, col_wrap=<span class="number">4</span>, height=<span class="number">3</span>, aspect=<span class="number">.8</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x140728250&gt;</code></pre><p><img src="data/output_89_1.png" alt="png"></p>
<p>上图表明，从第 4 次客服呼叫开始，Total day minutes 日通话分钟数 可能不再是客户离网（Churn==1）的主要因素。也许，除了我们之前猜测的话费原因，还有其他问题导致客户对服务不满意，这可能会导致日通话分钟数更少。</p>
<h4 id="类别与类别"><a href="#类别与类别" class="headerlink" title="类别与类别"></a>类别与类别</h4><p>正如之前提到的，变量 Customer service calls 客服呼叫数 的重复值很多，因此，既可以看成数值变量，也可以看成有序类别变量。之前已通过计数图（count plot）查看过它的分布了，现在我们感兴趣的是这一有序特征和目标变量 Churn 离网率 之间的关系。</p>
<p>使用 <code>countplot()</code> 方法查看客服呼叫数的分布，这次传入 <code>hue=Churn</code> 参数，以便在图形中加入类别维度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(x=<span class="string">'Customer service calls'</span>, hue=<span class="string">'Churn'</span>, data=df[df[<span class="string">"Customer service calls"</span>] &lt; <span class="number">10</span>])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x140cb7990&gt;</code></pre><p><img src="data/output_94_1.png" alt="png"></p>
<p>上图表明，呼叫客服达到 4 次以上后，离网率显著增加了。</p>
<p>使用 <code>countplot()</code> 方法查看 Churn 离网率 和二元特征 International plan 国际套餐、Voice mail plan 语音邮件套餐 的关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">_, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, sharey=<span class="literal">True</span>, figsize=(<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.countplot(x=<span class="string">'International plan'</span>, hue=<span class="string">'Churn'</span>, data=df, ax=axes[<span class="number">0</span>])</span><br><span class="line">sns.countplot(x=<span class="string">'Voice mail plan'</span>, hue=<span class="string">'Churn'</span>, data=df, ax=axes[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x142344290&gt;</code></pre><p><img src="data/output_97_1.png" alt="png"></p>
<p>上图表明，开通国际套餐后，离网率会高很多，即 International plan 是否开通国际套餐 是一个重要的特征。我们在 Vocie mail plan 语音邮件套餐 特征上没有观察到类似的效果。</p>
<h4 id="交叉表"><a href="#交叉表" class="headerlink" title="交叉表"></a>交叉表</h4><p>除了使用图形进行类别分析之外，还可以使用统计学的传统工具：交叉表（cross tabulation），即使用表格形式表示多个类别变量的频率分布。通过它可以查看某一列或某一行以了解某个变量在另一变量的作用下的分布情况。</p>
<p>通过交叉表查看 Churn 离网率 和类别变量 State 州 的关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.crosstab(df[<span class="string">'State'</span>], df[<span class="string">'Churn'</span>]).T</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>State</th>
      <th>AK</th>
      <th>AL</th>
      <th>AR</th>
      <th>AZ</th>
      <th>CA</th>
      <th>CO</th>
      <th>CT</th>
      <th>DC</th>
      <th>DE</th>
      <th>FL</th>
      <th>...</th>
      <th>SD</th>
      <th>TN</th>
      <th>TX</th>
      <th>UT</th>
      <th>VA</th>
      <th>VT</th>
      <th>WA</th>
      <th>WI</th>
      <th>WV</th>
      <th>WY</th>
    </tr>
    <tr>
      <th>Churn</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>False</th>
      <td>49</td>
      <td>72</td>
      <td>44</td>
      <td>60</td>
      <td>25</td>
      <td>57</td>
      <td>62</td>
      <td>49</td>
      <td>52</td>
      <td>55</td>
      <td>...</td>
      <td>52</td>
      <td>48</td>
      <td>54</td>
      <td>62</td>
      <td>72</td>
      <td>65</td>
      <td>52</td>
      <td>71</td>
      <td>96</td>
      <td>68</td>
    </tr>
    <tr>
      <th>True</th>
      <td>3</td>
      <td>8</td>
      <td>11</td>
      <td>4</td>
      <td>9</td>
      <td>9</td>
      <td>12</td>
      <td>5</td>
      <td>9</td>
      <td>8</td>
      <td>...</td>
      <td>8</td>
      <td>5</td>
      <td>18</td>
      <td>10</td>
      <td>5</td>
      <td>8</td>
      <td>14</td>
      <td>7</td>
      <td>10</td>
      <td>9</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 51 columns</p>
</div>



<p>上表显示，State 州 有 51 个不同的值，并且每个州只有 3 到 17 个客户抛弃了运营商。通过 <code>groupby()</code> 方法计算每个州的离网率，由高到低排列。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.groupby([<span class="string">'State'</span>])[<span class="string">'Churn'</span>].agg([np.mean]).sort_values(by=<span class="string">'mean'</span>, ascending=<span class="literal">False</span>).T</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>State</th>
      <th>NJ</th>
      <th>CA</th>
      <th>TX</th>
      <th>MD</th>
      <th>SC</th>
      <th>MI</th>
      <th>MS</th>
      <th>NV</th>
      <th>WA</th>
      <th>ME</th>
      <th>...</th>
      <th>RI</th>
      <th>WI</th>
      <th>IL</th>
      <th>NE</th>
      <th>LA</th>
      <th>IA</th>
      <th>VA</th>
      <th>AZ</th>
      <th>AK</th>
      <th>HI</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean</th>
      <td>0.264706</td>
      <td>0.264706</td>
      <td>0.25</td>
      <td>0.242857</td>
      <td>0.233333</td>
      <td>0.219178</td>
      <td>0.215385</td>
      <td>0.212121</td>
      <td>0.212121</td>
      <td>0.209677</td>
      <td>...</td>
      <td>0.092308</td>
      <td>0.089744</td>
      <td>0.086207</td>
      <td>0.081967</td>
      <td>0.078431</td>
      <td>0.068182</td>
      <td>0.064935</td>
      <td>0.0625</td>
      <td>0.057692</td>
      <td>0.056604</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 51 columns</p>
</div>



<p>上表显示，新泽西和加利福尼亚的离网率超过了 25%，夏威夷和阿拉斯加的离网率则不到 6%。然而，这些结论是基于极少的样本得出的，可能仅适用于这一特定数据集，不太具有泛用性。</p>
<h3 id="全局数据集可视化"><a href="#全局数据集可视化" class="headerlink" title="全局数据集可视化"></a>全局数据集可视化</h3><p>上面我们一直在研究数据集的不同方面（facet），通过猜测有趣的特征并一次选择少量特征进行可视化。如果我们想一次性显示所有特征并仍然能够解释生成的可视化，该怎么办？</p>
<h4 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h4><p>大多数现实世界的数据集有很多特征，每一个特征都可以被看成数据空间的一个维度。因此，我们经常需要处理高维数据集，然而可视化整个高维数据集相当难。为了从整体上查看一个数据集，需要在不损失很多数据信息的前提下，降低用于可视化的维度。这一任务被称为降维（dimensionality reduction）。降维是一个无监督学习（unsupervised learning）问题，因为它需要在不借助任何监督输入（如标签）的前提下，从数据自身得到新的低维特征。</p>
<p>主成分分析（Principal Component Analysis, PCA）是一个著名的降维方法，我们会在之后的课程中讨论它。但主成分分析的局限性在于，它是线性（linear）算法，这意味着对数据有某些特定的限制。</p>
<p>与线性方法相对的，有许多非线性方法，统称流形学习（Manifold Learning）。著名的流形学习方法之一是 t-SNE。</p>
<h3 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h3><p>本章节首先介绍了 Pandas、Matplotlib 和 seaborn 库的一些常用可视化方法，并对客户离网数据集进行了可视化分析和 t-SNE 降维。可视化是一个相对快捷的从数据中挖掘信息的手段，因此，学习这一技术并将其纳入你的日常机器学习工具箱，是很有必要的。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://edlison.com/blog/2020/05/17/mlsec/Python-%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E4%B9%8B%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90/" data-id="ckaat5bod0001vaojg5pm07mp" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/blog/">&amp;laquo; 上一页</a><a class="page-number" href="/blog/">1</a><span class="page-number current">2</span><a class="page-number" href="/blog/page/3/">3</a><a class="page-number" href="/blog/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/blog/page/8/">8</a><a class="extend next" rel="next" href="/blog/page/3/">下一页 &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/10/">十月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/09/">九月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/08/">八月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/03/">三月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/blog/2020/10/25/notebook/sql/">notebook/sql</a>
          </li>
        
          <li>
            <a href="/blog/2020/09/23/nlp/BERT/">nlp/BERT</a>
          </li>
        
          <li>
            <a href="/blog/2020/09/23/nlp/Transformer/">nlp/Transformer</a>
          </li>
        
          <li>
            <a href="/blog/2020/09/18/paper/Attention-Transformer/">paper/Attention-Transformer</a>
          </li>
        
          <li>
            <a href="/blog/2020/09/18/paper/XLNet/">paper/XLNet</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Bolin Shen<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/blog/" class="mobile-nav-link">Home</a>
  
    <a href="/blog/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css">

  
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>




<script src="/blog/js/script.js"></script>




  </div>
</body>
</html>