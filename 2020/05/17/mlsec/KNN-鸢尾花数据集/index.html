<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>mlsec/KNN-鸢尾花数据集 | Edlison</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="KNN-鸢尾花数据集123import numpy as npimport matplotlib.pyplot as pltfrom sklearn import datasets  使用sklearn本地数据集中的鸢尾花数据集12iris &#x3D; datasets.load_iris()iris.keys()     dict_keys([&amp;apos;data&amp;apos;, &amp;apos;target">
<meta property="og:type" content="article">
<meta property="og:title" content="mlsec&#x2F;KNN-鸢尾花数据集">
<meta property="og:url" content="http://edlison.com/blog/2020/05/17/mlsec/KNN-%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86/index.html">
<meta property="og:site_name" content="Edlison">
<meta property="og:description" content="KNN-鸢尾花数据集123import numpy as npimport matplotlib.pyplot as pltfrom sklearn import datasets  使用sklearn本地数据集中的鸢尾花数据集12iris &#x3D; datasets.load_iris()iris.keys()     dict_keys([&amp;apos;data&amp;apos;, &amp;apos;target">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-05-17T08:36:25.969Z">
<meta property="article:modified_time" content="2020-05-17T08:37:09.945Z">
<meta property="article:author" content="Bolin Shen">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/blog/atom.xml" title="Edlison" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/blog/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/blog/" id="logo">Edlison</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/blog/" id="subtitle">coding...</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/blog/">Home</a>
        
          <a class="main-nav-link" href="/blog/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/blog/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://edlison.com/blog"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-mlsec/KNN-鸢尾花数据集" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/17/mlsec/KNN-%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86/" class="article-date">
  <time datetime="2020-05-17T08:36:25.969Z" itemprop="datePublished">2020-05-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      mlsec/KNN-鸢尾花数据集
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="KNN-鸢尾花数据集"><a href="#KNN-鸢尾花数据集" class="headerlink" title="KNN-鸢尾花数据集"></a>KNN-鸢尾花数据集</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br></pre></td></tr></table></figure>

<h4 id="使用sklearn本地数据集中的鸢尾花数据集"><a href="#使用sklearn本地数据集中的鸢尾花数据集" class="headerlink" title="使用sklearn本地数据集中的鸢尾花数据集"></a>使用sklearn本地数据集中的鸢尾花数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris.keys()</span><br></pre></td></tr></table></figure>




<pre><code>dict_keys([&apos;data&apos;, &apos;target&apos;, &apos;target_names&apos;, &apos;DESCR&apos;, &apos;feature_names&apos;, &apos;filename&apos;])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = iris.data</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y = iris.target</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.shape</span><br></pre></td></tr></table></figure>




<pre><code>(150, 4)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y.shape</span><br></pre></td></tr></table></figure>




<pre><code>(150,)</code></pre><h1 id="手动分离测试数据"><a href="#手动分离测试数据" class="headerlink" title="手动分离测试数据"></a>手动分离测试数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shuffled_indexes = np.random.permutation(len(X))</span><br><span class="line">shuffled_indexes</span><br></pre></td></tr></table></figure>




<pre><code>array([ 47,  10, 144,  57, 135,  58,  36, 136,  73, 109,  64,  15, 104,
       143, 108,  83,  23, 126, 125, 131, 137,  22,  16,  29, 118,  31,
        33,  52,  32, 132,  45,  38,  78, 139,  30,  37,  61,  97, 122,
        56, 107,  66, 114,  87,  43,  76,  84,  79, 142,  70,  77,  42,
         7, 138, 141, 120, 129,  44,  24,  53, 116,  13,  91, 119,  93,
         6,  60,  50,  67,  20,  54,  71,  89,  68,  21, 133, 148,  81,
        25,  48, 130, 127,  28,  90,  82, 146, 100, 105,  80,  94,  14,
        55, 111, 106, 101, 103,  35,  99,   3,  26,  69, 124,  95,  96,
       140,  46,  19,  34,  75,  59,   1, 117, 121,  49, 110,   0, 115,
        72,   9,  18, 149,  40, 145,  92, 123,  51,   4,  11,  39,  85,
        62, 147, 102,  74,   2,  86,   8,  17,   5,  27, 112, 128,  12,
        65,  41, 134,  63,  88, 113,  98])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_ratio = <span class="number">0.2</span></span><br><span class="line">test_size = int(len(X) * test_ratio)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_indexes = shuffled_indexes[:test_size]</span><br><span class="line">train_indexes = shuffled_indexes[test_size:]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_train = X[train_indexes]</span><br><span class="line">Y_train = Y[train_indexes]</span><br><span class="line"></span><br><span class="line">X_test = X[test_indexes]</span><br><span class="line">Y_test = Y[test_indexes]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(X_train.shape);print(Y_train.shape);print(X_test.shape);print(Y_test.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(120, 4)
(120,)
(30, 4)
(30,)</code></pre><h1 id="使用sklearn分离"><a href="#使用sklearn分离" class="headerlink" title="使用sklearn分离"></a>使用sklearn分离</h1><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_test_split?</span><br></pre></td></tr></table></figure>


<pre><code>[0;31mSignature:[0m [0mtrain_test_split[0m[0;34m([0m[0;34m*[0m[0marrays[0m[0;34m,[0m [0;34m**[0m[0moptions[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;31mDocstring:[0m
Split arrays or matrices into random train and test subsets

Quick utility that wraps input validation and
``next(ShuffleSplit().split(X, y))`` and application to input data
into a single call for splitting (and optionally subsampling) data in a
oneliner.

Read more in the :ref:`User Guide &lt;cross_validation&gt;`.

Parameters
----------
*arrays : sequence of indexables with same length / shape[0]
    Allowed inputs are lists, numpy arrays, scipy-sparse
    matrices or pandas dataframes.

test_size : float, int or None, optional (default=None)
    If float, should be between 0.0 and 1.0 and represent the proportion
    of the dataset to include in the test split. If int, represents the
    absolute number of test samples. If None, the value is set to the
    complement of the train size. If ``train_size`` is also None, it will
    be set to 0.25.

train_size : float, int, or None, (default=None)
    If float, should be between 0.0 and 1.0 and represent the
    proportion of the dataset to include in the train split. If
    int, represents the absolute number of train samples. If None,
    the value is automatically set to the complement of the test size.

random_state : int, RandomState instance or None, optional (default=None)
    If int, random_state is the seed used by the random number generator;
    If RandomState instance, random_state is the random number generator;
    If None, the random number generator is the RandomState instance used
    by `np.random`.

shuffle : boolean, optional (default=True)
    Whether or not to shuffle the data before splitting. If shuffle=False
    then stratify must be None.

stratify : array-like or None (default=None)
    If not None, data is split in a stratified fashion, using this as
    the class labels.

Returns
-------
splitting : list, length=2 * len(arrays)
    List containing train-test split of inputs.

    .. versionadded:: 0.16
        If the input is sparse, the output will be a
        ``scipy.sparse.csr_matrix``. Else, output type is the same as the
        input type.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; X, y = np.arange(10).reshape((5, 2)), range(5)
&gt;&gt;&gt; X
array([[0, 1],
       [2, 3],
       [4, 5],
       [6, 7],
       [8, 9]])
&gt;&gt;&gt; list(y)
[0, 1, 2, 3, 4]

&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.33, random_state=42)
...
&gt;&gt;&gt; X_train
array([[4, 5],
       [0, 1],
       [6, 7]])
&gt;&gt;&gt; y_train
[2, 0, 3]
&gt;&gt;&gt; X_test
array([[2, 3],
       [8, 9]])
&gt;&gt;&gt; y_test
[1, 4]

&gt;&gt;&gt; train_test_split(y, shuffle=False)
[[0, 1, 2], [3, 4]]
[0;31mFile:[0m      /Applications/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py
[0;31mType:[0m      function</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(X_train.shape)</span><br><span class="line">print(Y_train.shape)</span><br><span class="line">print(X_test.shape)</span><br><span class="line">print(Y_test.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(120, 4)
(120,)
(30, 4)
(30,)</code></pre><h1 id="使用sklearn中的KNN分离器测试"><a href="#使用sklearn中的KNN分离器测试" class="headerlink" title="使用sklearn中的KNN分离器测试"></a>使用sklearn中的KNN分离器测试</h1><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">KNeighborsClassifier?</span><br></pre></td></tr></table></figure>


<pre><code>[0;31mInit signature:[0m
[0mKNeighborsClassifier[0m[0;34m([0m[0;34m[0m
[0;34m[0m    [0mn_neighbors[0m[0;34m=[0m[0;36m5[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mweights[0m[0;34m=[0m[0;34m&apos;uniform&apos;[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0malgorithm[0m[0;34m=[0m[0;34m&apos;auto&apos;[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mleaf_size[0m[0;34m=[0m[0;36m30[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mp[0m[0;34m=[0m[0;36m2[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mmetric[0m[0;34m=[0m[0;34m&apos;minkowski&apos;[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mmetric_params[0m[0;34m=[0m[0;32mNone[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0mn_jobs[0m[0;34m=[0m[0;32mNone[0m[0;34m,[0m[0;34m[0m
[0;34m[0m    [0;34m**[0m[0mkwargs[0m[0;34m,[0m[0;34m[0m
[0;34m[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;31mDocstring:[0m     
Classifier implementing the k-nearest neighbors vote.

Read more in the :ref:`User Guide &lt;classification&gt;`.

Parameters
----------
n_neighbors : int, optional (default = 5)
    Number of neighbors to use by default for :meth:`kneighbors` queries.

weights : str or callable, optional (default = &apos;uniform&apos;)
    weight function used in prediction.  Possible values:

    - &apos;uniform&apos; : uniform weights.  All points in each neighborhood
      are weighted equally.
    - &apos;distance&apos; : weight points by the inverse of their distance.
      in this case, closer neighbors of a query point will have a
      greater influence than neighbors which are further away.
    - [callable] : a user-defined function which accepts an
      array of distances, and returns an array of the same shape
      containing the weights.

algorithm : {&apos;auto&apos;, &apos;ball_tree&apos;, &apos;kd_tree&apos;, &apos;brute&apos;}, optional
    Algorithm used to compute the nearest neighbors:

    - &apos;ball_tree&apos; will use :class:`BallTree`
    - &apos;kd_tree&apos; will use :class:`KDTree`
    - &apos;brute&apos; will use a brute-force search.
    - &apos;auto&apos; will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, optional (default = 30)
    Leaf size passed to BallTree or KDTree.  This can affect the
    speed of the construction and query, as well as the memory
    required to store the tree.  The optimal value depends on the
    nature of the problem.

p : integer, optional (default = 2)
    Power parameter for the Minkowski metric. When p = 1, this is
    equivalent to using manhattan_distance (l1), and euclidean_distance
    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

metric : string or callable, default &apos;minkowski&apos;
    the distance metric to use for the tree.  The default metric is
    minkowski, and with p=2 is equivalent to the standard Euclidean
    metric. See the documentation of the DistanceMetric class for a
    list of available metrics.
    If metric is &quot;precomputed&quot;, X is assumed to be a distance matrix and
    must be square during fit. X may be a :term:`Glossary &lt;sparse graph&gt;`,
    in which case only &quot;nonzero&quot; elements may be considered neighbors.

metric_params : dict, optional (default = None)
    Additional keyword arguments for the metric function.

n_jobs : int or None, optional (default=None)
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details.
    Doesn&apos;t affect :meth:`fit` method.

Attributes
----------
classes_ : array of shape (n_classes,)
    Class labels known to the classifier

effective_metric_ : string or callble
    The distance metric used. It will be same as the `metric` parameter
    or a synonym of it, e.g. &apos;euclidean&apos; if the `metric` parameter set to
    &apos;minkowski&apos; and `p` parameter set to 2.

effective_metric_params_ : dict
    Additional keyword arguments for the metric function. For most metrics
    will be same with `metric_params` parameter, but may also contain the
    `p` parameter value if the `effective_metric_` attribute is set to
    &apos;minkowski&apos;.

outputs_2d_ : bool
    False when `y`&apos;s shape is (n_samples, ) or (n_samples, 1) during fit
    otherwise True.

Examples
--------
&gt;&gt;&gt; X = [[0], [1], [2], [3]]
&gt;&gt;&gt; y = [0, 0, 1, 1]
&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier
&gt;&gt;&gt; neigh = KNeighborsClassifier(n_neighbors=3)
&gt;&gt;&gt; neigh.fit(X, y)
KNeighborsClassifier(...)
&gt;&gt;&gt; print(neigh.predict([[1.1]]))
[0]
&gt;&gt;&gt; print(neigh.predict_proba([[0.9]]))
[[0.66666667 0.33333333]]

See also
--------
RadiusNeighborsClassifier
KNeighborsRegressor
RadiusNeighborsRegressor
NearestNeighbors

Notes
-----
See :ref:`Nearest Neighbors &lt;neighbors&gt;` in the online documentation
for a discussion of the choice of ``algorithm`` and ``leaf_size``.

.. warning::

   Regarding the Nearest Neighbors algorithms, if it is found that two
   neighbors, neighbor `k+1` and `k`, have identical distances
   but different labels, the results will depend on the ordering of the
   training data.

https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm
[0;31mFile:[0m           /Applications/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/_classification.py
[0;31mType:[0m           ABCMeta
[0;31mSubclasses:[0m     </code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">KNNClf = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">KNNClf.fit(X_train, Y_train)</span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsClassifier(algorithm=&apos;auto&apos;, leaf_size=30, metric=&apos;minkowski&apos;,
                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,
                     weights=&apos;uniform&apos;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">res = KNNClf.predict(X_test)</span><br><span class="line">res</span><br></pre></td></tr></table></figure>




<pre><code>array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,
       1, 0, 2, 1, 0, 0, 1, 2])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y_test</span><br></pre></td></tr></table></figure>




<pre><code>array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,
       1, 0, 2, 1, 0, 0, 1, 2])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">acc = sum(res == Y_test)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'accuracy '</span>, acc / len(Y_test))</span><br></pre></td></tr></table></figure>

<pre><code>accuracy  1.0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://edlison.com/blog/2020/05/17/mlsec/KNN-%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86/" data-id="ckaat5boe0002vaojg8iybnjo" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/blog/2020/05/17/mlsec/KNN-%E6%89%8B%E5%86%99%E4%BD%93%E6%95%B0%E5%AD%97%E6%95%B0%E6%8D%AE%E9%9B%86/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          mlsec/KNN-手写体数字数据集
        
      </div>
    </a>
  
  
    <a href="/blog/2020/05/17/mlsec/KNN-%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">mlsec/KNN-手动实现</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/03/">三月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/blog/2020/07/26/nlp/week-2/">nlp/week-2</a>
          </li>
        
          <li>
            <a href="/blog/2020/07/26/notebook/docker-nextcloud/">notebook/docker-nextcloud</a>
          </li>
        
          <li>
            <a href="/blog/2020/07/14/nlp/week-1/">nlp/week-1</a>
          </li>
        
          <li>
            <a href="/blog/2020/06/17/notebook/grpc/">notebook/grpc</a>
          </li>
        
          <li>
            <a href="/blog/2020/05/29/notebook/docker-gitlab/">notebook/docker-gitlab</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Bolin Shen<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/blog/" class="mobile-nav-link">Home</a>
  
    <a href="/blog/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css">

  
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>




<script src="/blog/js/script.js"></script>




  </div>
</body>
</html>